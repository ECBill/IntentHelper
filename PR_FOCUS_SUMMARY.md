# PR Summary: Focus State Machine Implementation

## Problem Solved

Replaced naive periodic LLM topic extraction with intelligent Focus State Machine addressing:
- âŒ Redundant topic judgments ("åˆ¤å®šäººç”Ÿçš„ä»·å€¼", "äººç”Ÿä»·å€¼çš„åˆ¤å®š"...)
- âŒ Too-fast weight decay losing multi-topic context
- âŒ Fragmented intent/topic/causal analysis
- âŒ Full refresh every 5 seconds causing instability

## Solution Overview

Unified focus tracking system with:
- âœ… Multi-dimensional scoring (recency, repetition, emotion, causal, drift)
- âœ… Intelligent deduplication and merging
- âœ… Slow-tail decay preserving relevant older topics
- âœ… 6-12 active + 8 latent focuses (adaptive)
- âœ… Drift trajectory prediction
- âœ… Incremental delta updates (no full refreshes)

## Changes

**Added (1,729 lines)**:
- `lib/models/focus_models.dart` - FocusPoint, transitions, deltas
- `lib/services/focus_drift_model.dart` - Trajectory tracking
- `lib/services/focus_state_machine.dart` - Main orchestrator
- `test/focus_state_machine_test.dart` - 20 unit tests
- `FOCUS_STATE_MACHINE.md` - Documentation

**Modified (+367 lines)**:
- `lib/services/human_understanding_system.dart` - Integration
- `lib/views/human_understanding_dashboard.dart` - New "å…³æ³¨ç‚¹" tab

## Key Algorithms

**Salience Score**:
```
S = 0.25*recency + 0.20*repetition + 0.15*emotion + 0.20*causal + 0.20*drift
```

**Recency Decay** (slow-tail):
```
f(Î”t) = 1 / (1 + (Î”t / 300)^0.7)
```

**Repetition** (log-scaled):
```
f(n) = log(1 + n) / log(21)
```

## Integration

```
Utterance â†’ FocusStateMachine â†’ Top 12 Focuses â†’ KnowledgeGraphManager
```

- Replaces old topic tracker as primary source
- Feeds knowledge graph retrieval
- Links focuses via causal relations
- Provides drift predictions

## Testing

- âœ… 20 unit tests (initialization, ingestion, merging, scoring, limiting, stats)
- ğŸ“‹ Manual validation: Dashboard â†’ "å…³æ³¨ç‚¹" tab

## Thesis Contribution

Solves "å¼€æ”¾å¼é•¿å¯¹è¯å®æ—¶è¯­éŸ³æµä¸‹ç”¨æˆ·å…³æ³¨ç‚¹æ¼‚ç§»å¯¼è‡´åç»­åšäº‹ä»¶å›¾è°±åŒ¹é…å›°éš¾" by maintaining persistent, multi-dimensional attention model feeding high-quality constraints to knowledge graph retrieval.
